ğŸ“˜ Dynamic Instructions in OpenAI Agents SDK


ğŸ§  Concept Introduction (Basic Idea)
ğŸ”¹ What are Instructions?
Agent ko guide karne ke liye hum usay ek prompt dete hain â€” isay instructions kehte hain.

Ye instructions hoti hain:

Agent ka tone, role, aur behavior define karti hain.

LLM ka thinking pattern inhi pe depend karta hai.

ğŸ”¹ Fixed vs Dynamic Instructions
âœ… Fixed Instructions (Normal Tarika)
Aap direct prompt de dete ho Agent create karte waqt:

python
Copy
Edit
agent = Agent(
    name="Helper",
    instructions="You are a helpful assistant.",
    model=model
)
Har run mein yehi static prompt use hota hai.

Har user ke liye same behavior.

No context-awareness.

ğŸ”„ Dynamic Instructions (Context-Aware Prompt)
Kabhi aapko chahiye ke:

Prompt har baar context ke mutabiq change ho.

Har user ke liye alag instructions generate ho.

Prompt personalize ho based on:

User role (admin/guest)

User name

Location, language, settings etc.

ğŸ§¬ How It Works Internally â€“ Lifecycle Breakdown
Letâ€™s break it down step by step:

âœ… Step 1: Agent receives dynamic function instead of static string
python
Copy
Edit
def dynamic_instructions(agent, context):
    if context.get("user") == "admin":
        return "You are a professional assistant. Respond formally."
    elif context.get("user") == "guest":
        return "You are a friendly assistant. Be casual and polite."
    else:
        return "You are a helpful assistant."

agent = Agent(
    name="SmartAgent",
    instructions=dynamic_instructions,
    model=model
)
ğŸ§  Behind the scenes:
instructions parameter is a callable (function) now.

SDK checks: Is it a str or a function?

If function â†’ call it at runtime with agent & context.

âœ… Step 2: You run the agent using Runner
python
Copy
Edit
Runner.run_sync(agent, input="Hello!", context={"user": "admin"})
âœ… Step 3: Instructions Function Gets Called Dynamically
Under the hood:

agent.instructions(agent, context) is invoked.

Jo return aata hai, wo final prompt ban jata hai.

python
Copy
Edit
# Internally:
instructions_prompt = agent.instructions(agent, context)
This prompt is passed to the LLM along with input.

âœ… Step 4: LLM Runs Based on Dynamic Prompt
Now the agent talks to LLM using this generated prompt.

So agar context mein user = "Ali" ho, the prompt might be:

â€œYou are a friendly assistant. Call the user by name Ali.â€

âœ… Step 5: Output Generated â†’ User gets context-aware answer
ğŸ“Š Visual Flow (Mentally)
text
Copy
Edit
[Runner.run()] 
   â†“
[Agent receives input + context]
   â†“
[Instructions Function is called â†’ Returns dynamic prompt]
   â†“
[LLM is called with final prompt + input]
   â†“
[LLM generates answer â†’ Output shown]
âœ… Use Cases (Kahan Useful Hai)
Scenario	Dynamic Behavior
ğŸ¤– Chatbot	Greet user by name, adjust tone
ğŸ” Role-based UI	Admins get strict response, users friendly
ğŸ§ª Testing	Inject instructions based on test case
ğŸ—£ï¸ Multi-lingual	Prompt generated based on preferred language

âš™ï¸ Advanced Version â€“ Async Function as Instructions
Instructions function async bhi ho sakti hai:

python
Copy
Edit
async def dynamic_instructions(agent, context):
    user_type = await get_user_type_from_api(context["user_id"])
    return f"You are a bot for a {user_type} user."

agent = Agent(instructions=dynamic_instructions, model=model)
SDK handles this await under the hood.

It awaits the instructions function if it's async.

â“ FAQ Section
Q: Kya har bar instructions function run hoti hai?
âœ… Haan, har Runner.run() ke time pe instructions regenerate hoti hain.

Q: Kya context required hai?
ğŸ“¦ Nahi â€” but recommended. You can pass custom context as dict.

Q: Kya ye tool_choice ke saath kaam karta hai?
ğŸ§  Bilkul. Dono parallel features hain.

âœ… Summary (In Short)
Feature	Explanation
instructions="..."	Static instructions (default)
instructions=function	Dynamic prompt generation
Accepts context?	âœ… Yes
Async supported?	âœ… Yes
Benefit	Personalized, context-aware behavior
Lifecycle?	Run-time evaluated for every Runner.run()